# Copyright 2018- The Pixie Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

''' Services Overview

 This script gets an overview all of the services in `namespace`.
'''
import px

ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)
# Flag to filter out requests that come from an unresolvable IP.
filter_unresolved_inbound = True
# Flag to filter out health checks from the data.
filter_health_checks = True
# Flag to filter out ready checks from the data.
filter_ready_checks = True
# Whether or not to include traffic from IPs that don't resolve to a known pod/service.
include_ips = True


def services(start_time: str, namespace: px.Namespace):
    ''' Get a list of the services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = px.DataFrame(table='process_stats', start_time=start_time)
    df.service = df.ctx['service']
    df = df[df.ctx['namespace'] == namespace and df.service != '']
    df.pod = df.ctx['pod']
    df = df.groupby(['service', 'pod']).agg()
    return df.groupby('service').agg(pod_count=('pod', px.count))


def inbound_service_let(start_time: str, namespace: px.Namespace):
    ''' Compute the let as a timeseries for requests received or by services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''

    # Calculate LET for each svc edge in the svc graph over each time window.
    # Each edge starts at a requester ('remote_addr') and ends at a
    # responder service.

    df = inbound_service_let_helper(start_time, namespace)
    # Filter only to inbound service traffic (server-side).
    # Don't include traffic initiated by this service to an external location.
    df = df[df.trace_role == 2]
    df = df.groupby(['timestamp', 'service']).agg(
        latency_quantiles=('latency', px.quantiles),
        error_rate=('failure', px.mean),
        throughput_total=('latency', px.count),
        inbound_bytes_total=('req_body_size', px.sum),
        outbound_bytes_total=('resp_body_size', px.sum)
    )

    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))

    df.request_throughput = df.throughput_total / window_ns
    df.inbound_throughput = df.inbound_bytes_total / window_ns
    df.outbound_throughput = df.outbound_bytes_total / window_ns
    df.error_rate = px.Percent(df.error_rate)
    df.time_ = df.timestamp

    return df[['time_', 'service', 'latency_p50', 'latency_p90',
               'latency_p99', 'request_throughput', 'error_rate',
               'inbound_throughput', 'outbound_throughput']]


def inbound_let_summary(start_time: str, namespace: px.Namespace):
    ''' Compute a summary of inbound traffic by requesting service, for requests
    on services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = inbound_service_let_helper(start_time, namespace)
    # Filter only to inbound service traffic (server-side).
    # Don't include traffic initiated by this service to an external location.
    df = df[df.trace_role == 2]
    df = df[df.service != '']
    df.responder = df.service
    df.requesting_ip = df.remote_addr
    df.requesting_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))
    df.requesting_svc = px.pod_id_to_service_name(px.ip_to_pod_id(df.remote_addr))

    per_ns_df = df.groupby(['timestamp', 'requesting_ip', 'requesting_pod', 'requesting_svc',
                            'responder']).agg(
        throughput_total=('latency', px.count),
        inbound_bytes_total=('req_body_size', px.sum),
        outbound_bytes_total=('resp_body_size', px.sum)
    )

    per_ns_df.request_throughput = per_ns_df.throughput_total / window_ns
    per_ns_df.inbound_throughput = per_ns_df.inbound_bytes_total / window_ns
    per_ns_df.outbound_throughput = per_ns_df.outbound_bytes_total / window_ns

    per_ns_df = per_ns_df.groupby(['requesting_ip', 'requesting_pod', 'requesting_svc',
                                   'responder']).agg(
        request_throughput=('request_throughput', px.mean),
        inbound_throughput=('inbound_throughput', px.mean),
        outbound_throughput=('outbound_throughput', px.mean)
    )

    quantiles_df = df.groupby(['requesting_ip', 'requesting_pod', 'requesting_svc',
                               'responder']).agg(
        latency=('latency', px.quantiles)
        error_rate=('failure', px.mean),
    )

    quantiles_df.error_rate = px.Percent(quantiles_df.error_rate)

    joined = per_ns_df.merge(quantiles_df, left_on=['requesting_ip', 'responder'],
                             right_on=['requesting_ip', 'responder'], how='inner',
                             suffixes=['', '_x'])
    return joined[['requesting_ip', 'requesting_pod', 'requesting_svc', 'responder', 'latency',
                   'request_throughput', 'error_rate', 'inbound_throughput', 'outbound_throughput']]


def inbound_let_service_graph(start_time: str, namespace: px.Namespace):
    ''' Compute a summary of traffic by requesting service, for requests on services in `namespace`.
        Similar to `inbound_let_summary` but also breaks down by pod in addition to service.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = inbound_service_let_helper(start_time, namespace)
    df = df.groupby(['timestamp', 'service', 'remote_addr', 'pod', 'trace_role']).agg(
        latency_quantiles=('latency', px.quantiles),
        error_rate=('failure', px.mean),
        throughput_total=('latency', px.count),
        inbound_bytes_total=('req_body_size', px.sum),
        outbound_bytes_total=('resp_body_size', px.sum)
    )

    # Get the traced and remote pod/service/IP information.
    df.traced_pod = df.pod
    df.traced_service = df.service
    df.traced_ip = px.pod_name_to_pod_ip(df.pod)

    localhost_ip_regexp = r'127\.0\.0\.[0-9]+'
    df.is_remote_addr_localhost = px.regex_match(localhost_ip_regexp, df.remote_addr)
    df.remote_pod = px.select(df.is_remote_addr_localhost,
                              df.pod,
                              px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr)))
    df.remote_service = px.select(df.is_remote_addr_localhost,
                                  df.traced_service,
                                  px.service_id_to_service_name(px.ip_to_service_id(df.remote_addr)))

    df.remote_ip = df.remote_addr
    # If external IPs are excluded in the service graph, then we also exclude any
    # traffic where we don't know the remote pod or remote service name.
    df = df[include_ips or (df.remote_pod != '' or df.remote_service != '')]

    # Associate it with Client/Server roles, based on the trace role.
    df.is_server_side_tracing = df.trace_role == 2
    df.responder_pod = px.select(df.is_server_side_tracing, df.traced_pod, df.remote_pod)
    df.requestor_pod = px.select(df.is_server_side_tracing, df.remote_pod, df.traced_pod)
    df.responder_service = px.select(df.is_server_side_tracing, df.traced_service, df.remote_service)
    df.requestor_service = px.select(df.is_server_side_tracing, df.remote_service, df.traced_service)
    df.responder_ip = px.select(df.is_server_side_tracing, df.traced_ip, df.remote_ip)
    df.requestor_ip = px.select(df.is_server_side_tracing, df.remote_ip, df.traced_ip)

    # Compute statistics about each edge of the service graph.
    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))
    df.request_throughput = df.throughput_total / window_ns
    df.inbound_throughput = df.inbound_bytes_total / window_ns
    df.outbound_throughput = df.outbound_bytes_total / window_ns
    df.error_rate = px.Percent(df.error_rate)

    return df.groupby(['responder_pod', 'requestor_pod', 'responder_service',
                       'requestor_service', 'responder_ip', 'requestor_ip']).agg(
        latency_p50=('latency_p50', px.mean),
        latency_p90=('latency_p90', px.mean),
        latency_p99=('latency_p99', px.mean),
        request_throughput=('request_throughput', px.mean),
        error_rate=('error_rate', px.mean),
        inbound_throughput=('inbound_throughput', px.mean),
        outbound_throughput=('outbound_throughput', px.mean),
        throughput_total=('throughput_total', px.sum)
    )


def inbound_service_let_helper(start_time: str, namespace: px.Namespace):
    ''' Compute the let as a timeseries for requests received or by services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.

    '''
    df = px.DataFrame(table='http_events', start_time=start_time)
    df.service = df.ctx['service']
    df.pod = df.ctx['pod_name']
    df = df[df.ctx['namespace'] == namespace]
    df = df[df.pod != '']
    df.latency = df.latency
    df.timestamp = px.bin(df.time_, window_ns)

    df.failure = df.resp_status >= 400
    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (
        df.req_path != '/readyz' or not filter_ready_checks)) and (
        df['remote_addr'] != '-' or not filter_unresolved_inbound)

    df = df[filter_out_conds]
    return df
